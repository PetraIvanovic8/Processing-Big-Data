# -*- coding: utf-8 -*-
"""ana_vis_dinh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/160gnuA9e2Cs2YgxSpPS5K2mcoFqgRGOp
"""

# import data management
import numpy as np
import pandas as pd
# from google.colab import files
from collections import Counter

# import visualization
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno

# import data processing
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, RobustScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, mutual_info_regression


# import models
from sklearn.linear_model import LinearRegression, Ridge, Lasso

# import performance metrics
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error, explained_variance_score
from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score, GridSearchCV
from sklearn.pipeline import Pipeline

# import basic functions
from IPython.display import display, clear_output
import warnings
warnings.filterwarnings('ignore')

# setting
pd.set_option('display.max_columns', None)
pd.set_option('display.float_format', lambda x: '%.5f' % x)
clear_output()

# read in pretty data
df_title = pd.read_csv("pre_process.csv")
df_title.drop('title',axis=1)
df_title.head()

# look at descriptive analytics of numerical columns
# NOTE: This matches the [summary.mean, summary.min, summary.max, summary.count] from ana_code_dinh.scala
# NOTE: Recreated for visualization and graphing support
df_title.head()
df_title.describe(exclude = 'object')

# view basic stats of categorical features
df_title.describe(exclude = ['float64', 'int64'])

# view column information
df_title.info(verbose = True)

# view distribution of variable of interest (gross)
# cutoff at 500Million for readability -> max is approx 750Million
plt.hist(df_title['gross'], range= (0, 450000000), bins = 150, edgecolor='black')
plt.title('Distribution of Life-time Gross');
plt.xlabel('Gross(In Hundreds of Millions)');
plt.ylabel('Frequency');

# group by content rating
df_title.contentRate.value_counts().plot(kind='barh', title='Content Rating Counts', xlabel='Counts', ylabel='Rating')

# line graph of runtime vs gross
df_title.sort_values(by=['rnTimeMin']).plot.scatter(x ='rnTimeMin',
                                                    y= 'gross',
                                                    s = 1,
                                                    grid = True,
                                                    title='Scatter of Length of Runtime vs Life-time Gross',
                                                    xlabel='Runtime (Min)',
                                                    ylabel='Gross (In Hundreds of Millions)')

# read in encoded data
# scale data to resemble normal
# tighten distribution range
df_encoded = pd.read_csv("process.csv")
df_encoded.drop('type', axis =1)
ss = StandardScaler()
mm = MinMaxScaler()
df_encoded[["rnTimeMin", "numVotes","imdbRtCnt" ,"imdbRtBest","imdbRtWorst","imdbRtAvg","slRateCnt","slRateAvg","gross"]] = ss.fit_transform(mm.fit_transform(df_encoded[["rnTimeMin", "numVotes","imdbRtCnt" ,"imdbRtBest","imdbRtWorst","imdbRtAvg","slRateCnt","slRateAvg","gross"]]))
df_encoded.head()

# corrrelation matrix -> use the label encoded and mm/ss dataframe
cm = df_encoded.corr()
ax = sns.heatmap(
    cm,
    vmin=-1, vmax=1, center=0,
    cmap=sns.diverging_palette(20, 220, n=200),
    square=True
)
ax.set_xticklabels(
    ax.get_xticklabels(),
    rotation=45,
    horizontalalignment='right'
);

# visualize the data leakage vs no data leakage
fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (12,5))
plt.subplot(1,1,1)
corr = df_encoded[["rnTimeMin", "numVotes","imdbRtCnt" ,"imdbRtBest","imdbRtWorst","imdbRtAvg","slRateCnt","slRateAvg","gross"]].corrwith(df_encoded['gross']).sort_values(ascending = False).to_frame()
corr.columns = ['gross']
sns.heatmap(corr,annot = True, cmap = 'magma',linewidths = 0.4,linecolor = 'black');
plt.title('Correlation w.r.t gross')

corr2 = df_encoded[['imdbRtCnt','numVotes','slRateCnt']].corrwith(df_encoded['imdbRtAvg']).sort_values(ascending = False).to_frame()
corr2.columns = ['imdbRtAvg']
corr2

corr3 = df_encoded[['imdbRtCnt','numVotes','slRateCnt']].corrwith(df_encoded['slRateAvg']).sort_values(ascending = False).to_frame()
corr3.columns = ['slRateAvg']
corr3